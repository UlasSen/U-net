{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\senol\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 256, 256, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6s/step - accuracy: 0.6204 - loss: 0.6408 - val_accuracy: 0.6484 - val_loss: 0.5687\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6s/step - accuracy: 0.6774 - loss: 0.5600 - val_accuracy: 0.7259 - val_loss: 0.4793\n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.7580 - loss: 0.4561 - val_accuracy: 0.7968 - val_loss: 0.3962\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.8705 - loss: 0.3080 - val_accuracy: 0.9338 - val_loss: 0.1479\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9511 - loss: 0.1292 - val_accuracy: 0.9793 - val_loss: 0.0629\n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9754 - loss: 0.0672 - val_accuracy: 0.9830 - val_loss: 0.0522\n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9805 - loss: 0.0562 - val_accuracy: 0.9820 - val_loss: 0.0484\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9813 - loss: 0.0511 - val_accuracy: 0.9844 - val_loss: 0.0439\n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9839 - loss: 0.0454 - val_accuracy: 0.9848 - val_loss: 0.0414\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9829 - loss: 0.0450 - val_accuracy: 0.9848 - val_loss: 0.0401\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9822 - loss: 0.0444 - val_accuracy: 0.9869 - val_loss: 0.0363\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9847 - loss: 0.0402 - val_accuracy: 0.9865 - val_loss: 0.0361\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9855 - loss: 0.0381 - val_accuracy: 0.9856 - val_loss: 0.0355\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9849 - loss: 0.0376 - val_accuracy: 0.9838 - val_loss: 0.0376\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9850 - loss: 0.0371 - val_accuracy: 0.9871 - val_loss: 0.0332\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6s/step - accuracy: 0.9846 - loss: 0.0377 - val_accuracy: 0.9888 - val_loss: 0.0301\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9866 - loss: 0.0339 - val_accuracy: 0.9869 - val_loss: 0.0314\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9856 - loss: 0.0349 - val_accuracy: 0.9892 - val_loss: 0.0286\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6s/step - accuracy: 0.9840 - loss: 0.0380 - val_accuracy: 0.9763 - val_loss: 0.0512\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5s/step - accuracy: 0.9805 - loss: 0.0437 - val_accuracy: 0.9846 - val_loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını yükle\n",
    "csv_path = './montgomery_metadata.csv'\n",
    "data_info = pd.read_csv(csv_path)\n",
    "\n",
    "# Veri yolları\n",
    "image_dir = './images/images'  # Görüntüler klasörü\n",
    "mask_dir = './images/masks'    # Maskeler klasörü\n",
    "image_size = (256, 256)  # Resimler ve maskeler için sabit boyut\n",
    "\n",
    "# 1. Veri Hazırlığı\n",
    "# CSV dosyasını kullanarak veri yükleme\n",
    "\n",
    "def load_data_with_csv(data_info, image_dir, mask_dir, image_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for _, row in data_info.iterrows():\n",
    "        # CSV'den görüntü ve maske isimlerini al\n",
    "        filename = row['study_id']\n",
    "\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        mask_path = os.path.join(mask_dir, filename)\n",
    "\n",
    "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "            # Görüntüyü ve maskeyi yükle\n",
    "            img = load_img(img_path, target_size=image_size)\n",
    "            mask = load_img(mask_path, target_size=image_size, color_mode='grayscale')\n",
    "\n",
    "            # Normalize et (0-1 arası)\n",
    "            images.append(img_to_array(img) / 255.0)\n",
    "            masks.append(img_to_array(mask) / 255.0)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Veriyi yükle\n",
    "images, masks = load_data_with_csv(data_info, image_dir, mask_dir, image_size)\n",
    "\n",
    "# Veriyi eğitim ve test setlerine böl\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. U-Net Modeli Tanımlama\n",
    "def unet_model(input_size):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u1 = layers.concatenate([u1, c2])\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u2 = layers.concatenate([u2, c1])\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c5)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Modeli derle\n",
    "model = unet_model((*image_size, 3))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Eğitim\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=16,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# Modeli kaydet\n",
    "model.save('unet_model_with_csv.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
